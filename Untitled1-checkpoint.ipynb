{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc994de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from bitarray import bitarray\n",
    "def bitarray_fromfile(fn):\n",
    "    try:\n",
    "        fh = open(fn, 'rb')\n",
    "        bits = bitarray()\n",
    "        bits.fromfile(fh)\n",
    "    except IOError as err:\n",
    "        logging.error(\"I/O error: %s\", err)\n",
    "        sys.exit(0)\n",
    "    return bits, fh\n",
    "import logging\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9abc10e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "sphincter = bitarray_fromfile('ENCFF335DOL.sphincter.bed.gz')\n",
    "lung = bitarray_fromfile('ENCFF972NPO.lungs.bed.gz')\n",
    "print(type(sphincter))\n",
    "\n",
    "\n",
    "#prefix_dir = \"Things I'm Being Forced to Write for My Degree\"\n",
    "\n",
    "fo = open(\"C:\\\\Users\\\\Goldfish\\\\Desktop\\\\Things I'm Being Forced to Write for My Degree\\\\CMSE 410\\\\ENCFF972NPO.lungs.bed.gz\",'rt')\n",
    "\n",
    "# check preexisting file\n",
    "#fa_fn = os.path.join(prefix_dir, 'fa', os.path.basename(fn))\n",
    "#if not os.path.isfile(fa_fn):\n",
    " #   logging.info(\"move fa to idx dir: %s\", fa_fn)\n",
    "  #  os.rename(fn, fa_fn)\n",
    "#try:\n",
    "# Open chromosome fa\n",
    "  #  logging.info(\"read fa file: %s\", chr)\n",
    " #   f = open('ENCFF972NPO.lungs.bed.gz', \"rt\")\n",
    "#except IOError as err: #error if it doesn't open\n",
    " #   logging.error(\"I/O error: %s\", err)\n",
    "  #  sys.exit(0)\n",
    "    \n",
    "#seq = fn.join(f.readlines()[1:]).strip() #skip the header, remove spaces\n",
    "#seq = seq.replace('\\n', '') #nuke the newline characters at the end of every line\n",
    "#f.close()\n",
    "\n",
    "    # N/gc/repeat bit array\n",
    "#    wchar_l = [\"nN\", \"cgCG\", \"acgt\"] #wildcard characters list\n",
    " #   barr_n  = [\"na\", \"cg\", \"rp\"] #bitarray\n",
    "    \n",
    "  #  arr_list = []\n",
    "   # for wchar, bn in zip(wchar_l, barr_n):#why are we zipping and unpacking at once\n",
    "    #    bit_fn  = os.path.join(prefix_dir, 'bit/%s.%s.bit' % (chr, bn))\n",
    "        #joined the given and bitarray\n",
    "     #   if not os.path.isfile(bit_fn):\n",
    "       #     logging.info(\"no wchar bit array for %s: making wcard bit index..\", chr)\n",
    "      #      arr = bitarray(map(lambda c: c in wchar, seq))\n",
    "\n",
    "            # save bit file\n",
    "        #    fo = open(bit_fn, 'wb')\n",
    "         #   arr.tofile(fo)\n",
    "          #  fo.close()\n",
    "        #else: #if it already exists don't make another one\n",
    "         #   logging.info(\"wchar bit array for %s already exists. loading ..\", chr)\n",
    "          #  arr, f = bitarray_fromfile(bit_fn)\n",
    "           # f.close()\n",
    "        #arr_list.append(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f509b147",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dir_this \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18m__file__\u001b[39m))\n\u001b[0;32m      2\u001b[0m dir_prnt \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(dir_this)\n\u001b[0;32m      3\u001b[0m base_data_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_prnt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "dir_this = os.path.dirname(os.path.abspath(__file__))\n",
    "dir_prnt = os.path.dirname(dir_this)\n",
    "base_data_dir = os.path.join(dir_prnt, \"data\")\n",
    "dir_scripts = os.path.join(dir_prnt, \"scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c06d2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "##null_seq gen sob\n",
    "def per_chrom_idx_bits(fn, prefix_dir, chr):\n",
    "\n",
    "    # check preexisting file\n",
    "    fa_fn = os.path.join(prefix_dir, 'fa', os.path.basename(fn))\n",
    "    if not os.path.isfile(fa_fn):\n",
    "        logging.info(\"move fa to idx dir: %s\", fa_fn)\n",
    "        os.rename(fn, fa_fn)\n",
    "    try:\n",
    "        # Open chromosome fa\n",
    "        logging.info(\"read fa file: %s\", chr)\n",
    "        f = open(fa_fn, \"r\")\n",
    "    except IOError as err: #error if it doesn't open\n",
    "        logging.error(\"I/O error: %s\", err)\n",
    "        sys.exit(0)\n",
    "    \n",
    "    seq = ''.join(f.readlines()[1:]).strip() #skip the header, remove spaces\n",
    "    seq = seq.replace('\\n', '') #nuke the newline characters at the end of every line\n",
    "    f.close()\n",
    "\n",
    "    # N/gc/repeat bit array\n",
    "    wchar_l = [\"nN\", \"cgCG\", \"acgt\"] #wildcard characters list\n",
    "    barr_n  = [\"na\", \"cg\", \"rp\"] #bitarray\n",
    "    \n",
    "    arr_list = []\n",
    "    for wchar, bn in zip(wchar_l, barr_n):#why are we zipping and unpacking at once\n",
    "        bit_fn  = os.path.join(prefix_dir, 'bit/%s.%s.bit' % (chr, bn))\n",
    "        #joined the given and bitarray\n",
    "        if not os.path.isfile(bit_fn):\n",
    "            logging.info(\"no wchar bit array for %s: making wcard bit index..\", chr)\n",
    "            arr = bitarray(map(lambda c: c in wchar, seq))\n",
    "\n",
    "            # save bit file\n",
    "            fo = open(bit_fn, 'wb')\n",
    "            arr.tofile(fo)\n",
    "            fo.close()\n",
    "        else: #if it already exists don't make another one\n",
    "            logging.info(\"wchar bit array for %s already exists. loading ..\", chr)\n",
    "            arr, f = bitarray_fromfile(bit_fn)\n",
    "            f.close()\n",
    "        arr_list.append(arr)\n",
    "\n",
    "    del seq\n",
    "    return arr_list\n",
    "\n",
    "##Sliding window with t and calculate rp/gc counts\n",
    "def flatten(l):\n",
    "    for el in l: #I think this just makes the bitarrays iterable again\n",
    "        if isinstance(el, Iterable) and not isinstance(el, (str, bytes)):\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "           yield el\n",
    "def per_chrom_nidx_l(fn, prefix_dir, chr, t, arr_list):\n",
    "\n",
    "    nidx_pos_fn = os.path.join(prefix_dir, 'nidx_t%d/%s_pos.npy' % (t, chr))\n",
    "    nidx_ptr_fn = os.path.join(prefix_dir, 'nidx_t%d/%s_ptr.npz' % (t, chr))\n",
    "\n",
    "    if not (os.path.isfile(nidx_pos_fn) and os.path.isfile(nidx_ptr_fn)):\n",
    "    #if there isn't an index file and a pointer file, make them\n",
    "        # 3D-list for build index\n",
    "        nidx_l = [[[] for col in range(t+1)] for row in range(t+1)] \n",
    "\n",
    "        # N/gc/repeat bit array\n",
    "        na_arr, cg_arr, rp_arr = arr_list\n",
    "        \n",
    "        # scan with t-bp window\n",
    "        # sliding and calculate the cnt of wildcard char\n",
    "        na_cnt_c = na_arr[:t].count(True)\n",
    "        cg_cnt_c = cg_arr[:t].count(True)\n",
    "        rp_cnt_c = rp_arr[:t].count(True)\n",
    "\n",
    "        logging.info(\"making nulls index for %s\", fn)\n",
    "        for i in range(0, len(na_arr) - t):\n",
    "            # indexing only for regions with N-count = 0\n",
    "            if not na_cnt_c:\n",
    "                nidx_l[cg_cnt_c][rp_cnt_c].append(i) # start from 0\n",
    "\n",
    "            # to minimize exhausitive count of trues\n",
    "            na_cnt_c += (int(na_arr[i + t]) - int(na_arr[i]))\n",
    "            cg_cnt_c += (int(cg_arr[i + t]) - int(cg_arr[i]))\n",
    "            rp_cnt_c += (int(rp_arr[i + t]) - int(rp_arr[i]))\n",
    "        \n",
    "        n = 0\n",
    "        nidx_ptr = np.ones(shape=(t+1, t+1), dtype=np.int32)\n",
    "        for i, nl in enumerate(nidx_l):\n",
    "            for j, el in enumerate(nl):\n",
    "                nidx_ptr[i][j] = n\n",
    "                n += len(el)\n",
    "\n",
    "        np.savez_compressed(nidx_ptr_fn, ptr=nidx_ptr, len=n)\n",
    "        del nidx_ptr\n",
    "        \n",
    "        nidx_pos = np.fromiter(flatten(nidx_l), count=-1, dtype=np.int32)\n",
    "        del nidx_l\n",
    "        \n",
    "        # save nidx mat\n",
    "        np.save(nidx_pos_fn, nidx_pos)\n",
    "        del nidx_pos_fn\n",
    "\n",
    "    else:\n",
    "        logging.info(\"already have nidx_pos/ptr matrices for %s, skip.\", fn)\n",
    "\n",
    "##process function\n",
    "\n",
    "def _proc_build_idx_func(fn, t, prefix_dir):\n",
    "\n",
    "    chr = '.'.join(os.path.basename(fn).split('.')[:-1])\n",
    "    barr_list = per_chrom_idx_bits(fn, prefix_dir, chr)\n",
    "    per_chrom_nidx_l(fn, prefix_dir, chr, t, barr_list)\n",
    "    \n",
    "    #This is file processing stuff\n",
    "    \n",
    "    return 0 # dummy output\n",
    "\n",
    "def pool_wrapper_nidx_build(args):\n",
    "    return _proc_build_idx_func(*args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "996d1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "##MAKE PROFILES\n",
    "\n",
    "def make_profile(bed_file, prof_file, genome_assembly):\n",
    "    #load the bit arrays as dictionaries\n",
    "    arr_cg_dic = {} #c vs. g content\n",
    "    arr_rp_dic = {} #repeats\n",
    "    arr_na_dic = {} #N's in the nucleotide sequence\n",
    "    \n",
    "    def get_bit_array(genome_assembly, chr, pr):\n",
    "        bit_dir = os.path.join(os.path.join(base_data_dir, genome_assembly, \"bit\"))\n",
    "        return bitarray_fromfile(os.path.join(bit_dir, \"%s.%s.bit\" % (chr, pr)))[0]\n",
    "    \n",
    "    f = open(bed_file) #open the given sequence file to read\n",
    "    fo = open(prof_file, \"w\") #open profile file to write to\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        line_tab = line.split()\n",
    "        chr = line_tab[0]\n",
    "        start = int(line_tab[1])\n",
    "        end = int(line_tab[2])\n",
    "        seq_len = end - start #length of the target sequence\n",
    "        seq_id = '%s:%d-%d' % (chr, start+1, end) #name for the sequence, this gets\n",
    "                                                #added to the file name later iirc\n",
    "        \n",
    "        #Count the GC content\n",
    "        if not chr in arr_cg_dic:\n",
    "            arr_cg_dic[chr] = get_bit_array(genome_assembly, chr, \"gc\")\n",
    "        cg = arr_cg_dic[chr][start:end].count(True) / seq_len\n",
    "        \n",
    "        #Count the Repeat content\n",
    "        if not chr in arr_na_dic:\n",
    "            arr_rp_dic[chr] = get_bit_array(genome_assembly, chr, \"rp\")\n",
    "        rp = arr_rp_dic[chr][start:end].count(True) / seq_len\n",
    "        \n",
    "        #Count the nN content\n",
    "        if not chr in arr_na_dic:\n",
    "            arr_na_dic[chr] = get_bit_array(genome_assembly, chr, \"na\")\n",
    "        na = arr_na_dic[chr][start:end].count(True) / seq_len\n",
    "        \n",
    "        #Writing the content reads, seq_id and seq_len to the file\n",
    "        fo.write('\\t'.join(map(str, [seq_id, seq_len, cg, rp, na])) + '\\n')\n",
    "    \n",
    "    #Can't forget to close them uwu    \n",
    "    fo.close()\n",
    "    f.close()\n",
    "    \n",
    "##Note from the original script for quality control\n",
    "        ## QC to make a positive set\n",
    "         # score_col: 7 - hotspot2, 8 - macs2\n",
    "        \n",
    "##This part is prep for the statistical validation where it random generates\n",
    "# positive sets to compare against the actual generated results\n",
    "## something about the trial number runs and p-values for the results\n",
    "def make_qc_posset(gkmqc_out_dir, args):\n",
    "    \n",
    "    peak_file = args.peak_file #file with generated important peaks\n",
    "    prefix = args.name #filename prefix for file consistency\n",
    "    window_bp = args.window_bp #size of window\n",
    "    genome_assembly = args.genome_assembly #which reference genome\n",
    "    score_col = args.score_col #\n",
    "    \n",
    "    #FILES\n",
    "    ext_len = window_bp / 2 #not sure what ext_len stands for\n",
    "    #extraction length maybe? since it's based on the window size\n",
    "    prefix = \"%s.e%d\" % (prefix, ext_len)\n",
    "    posf0 = \"%s.bed\" % prefix #given file\n",
    "    posf0_prof = \"%s.prof\" % prefix #file w/ (gc, na, rp) profile for given file\n",
    "    posf = \"%s.qc.bed\" % prefix #quality control file\n",
    "    \n",
    "    #Step 1 make fixed length peaks\n",
    "    ## makes it so that the peaks in the quality-check generations have the same\n",
    "    #  size as the SVM generated peaks\n",
    "    logging.info(\"make fixed length peaks\")\n",
    "    if os.path.isfile(posf0): #if the file exists...\n",
    "        logging.info(\"skip making %s\", posf0) #don't make one\n",
    "    else:\n",
    "        os.system(\"awk -v OFS='\\t' -v SHFT=%d '$1 ~ /^chr[0-9XY]+$/ && $2+$10 > SHFT {\\\n",
    "            summit=$2+$10; print $1,summit-SHFT,summit+SHFT,$4,$%d}' %s >%s\" %\\\n",
    "                 (exit_len, score_col, peak_file, posf0))\n",
    "            #even if u held me at gunpoint I couldn't tell u what all that in the \"\" is saying\n",
    "    \n",
    "    #Step 2 calculate the (gc, na, rp) profiles of the fixed length peaks\n",
    "    ##this is to make sure that all the peaks generated have the same qualities\n",
    "    # as the peaks generated during the SVM\n",
    "    logging.info(\"calculate gc/rp/na profiles of the fixed length peaks\")\n",
    "    skip_flag = False\n",
    "    if os.path.isfile(posf0_prof): #if there's already a positive profile\n",
    "        nb = sum(1 for line in open(posf0))\n",
    "        np = sum(1 for line in open(posf0_prof)) #this is referencing the bitarrays\n",
    "                                                #which are stores as 1s + 0s\n",
    "        if nb == np:\n",
    "            logging.info(\"skip making %s\", posf0_prof)\n",
    "            skip_flag = True #don't make a profile\n",
    "    if not skip_flag:\n",
    "        make_profile(posf0, posf0_prof, genome_assembly) #make a profile\n",
    "        \n",
    "    #Step 3. Filter out junk parts of the bed file\n",
    "    #by junk I mean stuff that is noise (repeats) and stuff that isn't \n",
    "    #real nucleotides/unsure nucleotides (the N's)\n",
    "    logging.info(\"remove peaks with >1% of N bases and >70% of repeats\")\n",
    "    if os.path.isfile(posf): #if the file exists\n",
    "        logging.info(\"skip making %s\", posf) #don't make one\n",
    "    else:\n",
    "        os.system(\"paste %s %s | awk '$4<=0.7 && $5<=0.01' | cut -f 6- >%s\" %\\\n",
    "                 (posf0_prof, posf0, posf))\n",
    "        #cut anything that isn't within the acceptable range\n",
    "        #past anything that IS within the acceptable range\n",
    "    \n",
    "#Step 4. spkit the positive set by p-value\n",
    "## we have reached the statistics part\n",
    "\n",
    "def split_posset(gkmqc_out_dir, args):\n",
    "    prefix = args.name\n",
    "    window_bp = args.window_bp\n",
    "    split_n = args.split_n\n",
    "    \n",
    "    #FILES\n",
    "    ext_len = window_bp / 2\n",
    "    prefix = \"%s.e%d\" % prefix\n",
    "    \n",
    "    #Read\n",
    "    ntot = 0 #n total\n",
    "    posf_l = [] #positive list\n",
    "    f = open(posf)\n",
    "    for line in f.readlines():\n",
    "        #ch = ;s = ;e = ;sid = seq_id;score = seq_score\n",
    "        ch, s, e, sid, score = line.split()\n",
    "        posf_l.append((ch,int(s),int(e),sid,float(score)))\n",
    "        ntot += 1\n",
    "    f.close()\n",
    "    \n",
    "    ntests = int((ntot + int(split_n / 2)) / split_n)\n",
    "    \n",
    "    #Sort\n",
    "    logging.info(\"sort peaks\")\n",
    "    posf_l.sort(key=lambda x: x[4], reverse=True) #sort scores\n",
    "    posf_lr = [] #reverse list?\n",
    "    prev_score = posf_l[0][4] #score of first line lol\n",
    "    prev_argi = 0\n",
    "    for i, posf_e in enumerate(posf_l):\n",
    "        if posf_e[4] != prev_score or i == len(posf_l) - 1: #keep shuffling until\n",
    "            sub = posf_l[prev_argi:1]                 #u run out of runs to sort\n",
    "            if len(sub) > 1: random.shuffle(sub) #random shuffle peaks with same signal\n",
    "            post_lr += sub\n",
    "            prev_score = posf_e[4]\n",
    "            prev_argi = i\n",
    "    del posf_l #bc it's been replaced with the sorted list\n",
    "    \n",
    "    #Split\n",
    "    logging.info(\"split processing\")\n",
    "    for i in range(ntests):\n",
    "        s = split_n * i\n",
    "        if i == ntests - 1: e = ntot\n",
    "        else: e = split_n * (i + 1)\n",
    "        \n",
    "        fo = open(\"%s.top%d.bed\" % (posf[:-4], i+1), \"w\")\n",
    "        for line in sorted(posf_lr[s:e]):\n",
    "            fo.write('\\t'.join(map(str,line)) + '\\n')\n",
    "        fo.close()\n",
    "        \n",
    "    return ntests\n",
    "\n",
    "##Generate a negative set for each of the splitted positive sets (rank start and end)\n",
    "\n",
    "def make_negset(gkmqc_out_dir, args):\n",
    "    \n",
    "    prefix = args.name\n",
    "    window_bp = args.window_bp\n",
    "    genome = args.genome_assembly\n",
    "    rank_start = args.rank_start\n",
    "    rank_end = args.rank_end\n",
    "    rseed = args.random_seeds\n",
    "    p = args.n_processes\n",
    "    gc_margini = args.marginal_gc\n",
    "    rp_margin = args.marginal_rp\n",
    "    \n",
    "    #FILES\n",
    "    ext_len = window_bp / 2\n",
    "    prefix = \"%s.e%d\" % (prefix, ext_len)\n",
    "    \n",
    "    pos_bed_files = list(map(lambda x: \"%s.qc.top%d.bed\" % (prefix, x), range(rank_start, rank_end + 1)))\n",
    "    neg_bed_files = list(map(lambda x: \"%s.qc.top%d.nr1.bed\" % (prefix, x), range(rank_start, rank_end + 1)))\n",
    "    \n",
    "    pos_exist_l = len([f for f in pos_bed_files if os.path.isfile(f)])\n",
    "    neg_exist_l = len([f for f in neg_bed_files if os.path.isfile(f)])\n",
    "    \n",
    "    if pos_exist_l == neg_exist_l: ##if they're the same length\n",
    "        logging.info(\"skip making negative set\") #ur already there don't make more\n",
    "    else:\n",
    "        #Generate null seq\n",
    "        args_nseq_gen = [genome, window_bp, rseed, p, gc_margin, rp_margin]\n",
    "        fetch_nullseq_beds(pos_bed_files, neg_bed_files, args_nseq_gen)\n",
    "        \n",
    "    return(pos_bed_files, neg_bed_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04608e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
